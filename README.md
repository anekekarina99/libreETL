# ğŸ› ï¸ Zero-Cost ETL Project Boilerplate = liberETL

A **lightweight, zero-cost ETL project template** for learning and collaboration.  
Built to help anyone practice ETL workflows using free tools, while maintaining  
**data governance, security, and collaboration standards** â€” without relying on CI/CD or expensive cloud platforms.

---

## ğŸ“‚ Project Structure

```
my_zero_cost_etl_project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # Original raw files (do not modify)
â”‚   â”‚   â”œâ”€â”€ sales_20250922_v1.csv
â”‚   â”‚   â””â”€â”€ external_api_20250922_v1.json
â”‚   â”œâ”€â”€ processed/             # Cleaned & transformed datasets
â”‚   â”‚   â””â”€â”€ sales_cleaned_20250922_v1.parquet
â”‚   â”œâ”€â”€ database/              # Small databases (SQLite, etc.)
â”‚   â”‚   â””â”€â”€ my_database.db
â”‚   â””â”€â”€ samples/               # Small datasets (â‰¤1MB) for testing
â”‚       â””â”€â”€ sample_sales.csv
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ README.md              # Project documentation
â”‚   â”œâ”€â”€ data_dictionary.md     # Dataset field definitions
â”‚   â”œâ”€â”€ data_standards.md      # Naming & formatting rules
â”‚   â””â”€â”€ governance.md          # Governance policies
â”œâ”€â”€ logs/                      # ETL logs
â”œâ”€â”€ scripts/                   # Python ETL scripts
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ load.py
â”‚   â””â”€â”€ run_etl_pipeline.py
â”œâ”€â”€ .gitignore
â””â”€â”€ requirements.txt
```

---

## ğŸ“‹ Requirements

Dependencies are listed in `requirements.txt`:

- **pandas** â†’ data manipulation  
- **requests** â†’ API extraction  
- **sqlalchemy** â†’ SQL operations  
- **pyarrow** â†’ Parquet support  
- **openpyxl**, **xlrd** â†’ Excel file support  
- **python-dotenv** â†’ environment variable handling  
- **numpy**, **python-dateutil** â†’ core dependencies  

Install with:

```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
pip install -r requirements.txt
```

---

## ğŸ”‘ Data Governance

See [`docs/governance.md`](docs/governance.md) for full details.
Key rules:

* **Folder usage**

  * `data/raw` â†’ raw/original files (immutable)
  * `data/processed` â†’ cleaned outputs
  * `data/database` â†’ SQLite or small databases
  * `data/samples` â†’ â‰¤1MB datasets for quick testing

* **File naming convention**

  ```
  {datasetName}_{YYYYMMDD}_{v#}.{ext}
  ```

  Example: `sales_20250922_v1.csv` â†’ `sales_20250922_v2.csv`

* **File size limits**

  * â‰¤50MB per file inside repo
  * Larger datasets â†’ external storage (Google Drive, etc.)

* **Security**

  * Never commit `.env`, API keys, or sensitive data
  * `.gitignore` already excludes secrets and credentials

---

## ğŸ¤ Collaboration

This repo is **open for direct commits** (no pull requests required).
Each contributor is responsible for following standards:

* Respect file naming rules (`docs/data_standards.md`)
* Keep raw data unchanged
* Place experiments under `scripts/experimental/`
* Update documentation when adding datasets or transformations

---

## ğŸš€ How to Use

1. Put your raw files into `data/raw/`
2. Write extraction code in `scripts/extract.py`
3. Apply transformations in `scripts/transform.py`
4. Load into SQLite (`data/database/`) via `scripts/load.py`
5. Run the pipeline with `scripts/run_etl_pipeline.py`

---

## ğŸ“– Documentation

* **`README.md`** â†’ project overview
* **`data_dictionary.md`** â†’ field definitions for datasets
* **`data_standards.md`** â†’ naming and formatting rules
* **`governance.md`** â†’ governance and collaboration policies

---

## ğŸŒ± Philosophy

This boilerplate is designed to be:

* **Zero-cost** â†’ no paid tools required
* **Lightweight** â†’ no CI/CD or complex setup
* **Collaborative** â†’ open contributions, minimal barriers
* **Disciplined** â†’ structure and governance instead of heavy monitoring

```
Simple rules > Expensive tools  
Shared responsibility > Strict gatekeeping
```

---

ğŸ”¥ Ready to start building ETL pipelines without cloud overhead!